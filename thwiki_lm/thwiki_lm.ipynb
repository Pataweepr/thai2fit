{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thai2fit Language Model Pre-training\n",
    "\n",
    "The goal of this notebook is to train a language model using the [fast.ai](http://www.fast.ai/) version of [AWD LSTM Language Model](https://arxiv.org/abs/1708.02182), with data from [Thai Wikipedia Dump](https://dumps.wikimedia.org/thwiki/latest/thwiki-latest-pages-articles.xml.bz2) last updated February 17, 2019. Using 40M/200k/200k tokens of train-validation-test split, we achieved validation perplexity of **51.6376 with 60,003 embeddings at 400 dimensions**, compared to state-of-the-art as of October 27, 2018 at **42.41 for English WikiText-2 by [Yang et al (2018)](https://arxiv.org/abs/1711.03953)**. To the best of our knowledge, there is no comparable research in Thai language at the point of writing (February 17, 2019).\n",
    "\n",
    "Our workflow is as follows:\n",
    "\n",
    "* Retrieve and process [Thai Wikipedia Dump](https://dumps.wikimedia.org/thwiki/latest/thwiki-latest-pages-articles.xml.bz2) according to [n-waves/ulmfit-multilingual](https://github.com/n-waves/ulmfit-multilingual)\n",
    "* Perform 40M/200k/200k tokens of train-validation-test split split\n",
    "* Minimal text cleaning and tokenization using `newmm` with frozen dictionary (`engine='ulmfit'`) of [pyThaiNLP](https://github.com/pyThaiNLP/pythainlp/)\n",
    "* Train language model\n",
    "* Evaluate model based on perplexity and eyeballing\n",
    "* Extract embeddings to use as \"word2vec\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T03:30:25.407566Z",
     "start_time": "2018-01-25T03:30:21.597641Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai import *    \n",
    "from fastai.text import * \n",
    "from fastai.callbacks import CSVLogger\n",
    "\n",
    "data_path = 'th-all-unk/'\n",
    "model_path = 'thwiki_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We follow the dataset creation, pre- and post-processing of [n-waves/ulmfit-multilingual](https://github.com/n-waves/ulmfit-multilingual):\n",
    "\n",
    "* `ulmfit/create_wikitext.py` - Download thwiki in json format and separate them into 40M/200k/200k tokens of train-validation-test split. Articles with least than 100 tokens are removed. Also perform tokenization with whitespaces as separators.\n",
    "* `ulmfit/postprocess_wikitext.py` - Replace numbers and replace out-of-vocabulary tokens with `xxunk` (frequency of less than 3).\n",
    "\n",
    "We replaced the Moses Tokenizer with the following code to use [pyThaiNLP](https://github.com/pyThaiNLP/pythainlp/)'s `newmm` dictionary-based tokenizer with a frozen dictionary instead. We join the tokens within an article together to be tokenized later by the data bunch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.tokenize import word_tokenize\n",
    "class ThaiNLPTokenizer:\n",
    "    def __init__(self,engine='ulmfit'):\n",
    "        self.engine='ulmfit'\n",
    "    def tokenize(self, t, return_str=True):\n",
    "        res = word_tokenize(t,self.engine)\n",
    "        return ' '.join(res) if return_str else res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the statistics of the dataset:\n",
    "\n",
    "```\n",
    "before postprocessing\n",
    "# documents: 121,027. # tokens: 39,378,410\n",
    "\n",
    "after postprocessing\n",
    "OOV ratio: 0.0042\n",
    "data/wiki/th-all vocab size: 111,224\n",
    "th.wiki.train.tokens. # of tokens: 41,482,435\n",
    "th.wiki.valid.tokens. # of tokens: 200,563\n",
    "th.wiki.test.tokens. # of tokens: 200,827\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snippet from https://github.com/n-waves/ulmfit-multilingual/blob/master/ulmfit/pretrain_lm.py\n",
    "def istitle(line):\n",
    "    return len(re.findall(r'^ ?= [^=]* = ?$', line)) != 0\n",
    "\n",
    "def read_wiki_articles(filename):\n",
    "    articles = []\n",
    "    with open(filename, encoding='utf8') as f:\n",
    "        lines = f.readlines()\n",
    "    current_article = []\n",
    "    for i,line in enumerate(lines):\n",
    "        current_article.append(line)\n",
    "        if i < len(lines)-2 and lines[i+1].strip() == \"\" and istitle(lines[i+2]):\n",
    "            articles.append(\"\".join(current_article))\n",
    "            current_article = []\n",
    "    articles.append(\"\".join(current_article))\n",
    "    print(f\"Wiki text was split to {len(articles)} articles\")\n",
    "    return pd.DataFrame({'texts': np.array(articles, dtype=np.object)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiki text was split to 53308 articles\n",
      "Wiki text was split to 315 articles\n",
      "Wiki text was split to 268 articles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((53307, 1), (314, 1), (267, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#last line is corrupted\n",
    "train_df = read_wiki_articles(f'{data_path}th.wiki.train.tokens').iloc[:-1,:]\n",
    "valid_df = read_wiki_articles(f'{data_path}th.wiki.valid.tokens').iloc[:-1,:]\n",
    "test_df = read_wiki_articles(f'{data_path}th.wiki.test.tokens').iloc[:-1,:]\n",
    "train_df.shape, valid_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join tokens together\n",
    "train_df['texts'] = train_df.texts.map(lambda x: ''.join(x.split()))\n",
    "valid_df['texts'] = valid_df.texts.map(lambda x: ''.join(x.split()))\n",
    "test_df['texts'] = test_df.texts.map(lambda x: ''.join(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "We used the `newmm` engine of `pyThaiNLP` to perform tokenization. Out of randomnum tokens from all of training set, we chose 60,000 embeddings (plus two for unknown and padding) of tokens which appeared more than twice (not typos) in the training set.\n",
    "\n",
    "\n",
    "We perform the following text processing:\n",
    "\n",
    "* Fix html tags to plain texts\n",
    "* Lowercase all English words and if a word is written in all caps, we put it in a lower case and add `xxup` before\n",
    "* Repetitive characters: Thai usually emphasizes adjectives by repeating the last character such as `อร่อยมากกกกกกก` to `อร่อยมาก xxrep 7 ` so that the word still retains its original form. \n",
    "* Normalize character order: for instance `นำ้` to `น้ำ`\n",
    "* Add spaces around / and #\n",
    "* Remove multiple spaces and newlines\n",
    "* Remove empty brackets of all types (`([{`) which might result from cleaning up\n",
    "* `pyThaiNLP`'s `newmm` word tokenizer with frozen dictionary (`engine ='ulmfit'`)  is used to tokenize the texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thai Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `newmm` tokenizer with a dictionary frozen as of 2018-10-23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T15:50:02.035245Z",
     "start_time": "2018-01-24T15:50:01.940191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['วิทยาศาสตร์',\n",
       " 'ดาวเคราะห์',\n",
       " 'เป็น',\n",
       " 'สาขาวิชา',\n",
       " 'ที่',\n",
       " 'ศึกษา',\n",
       " 'เกี่ยวกับ',\n",
       " 'องค์ประกอบ',\n",
       " 'ของ',\n",
       " 'ดาวเคราะห์']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='วิทยาศาสตร์ดาวเคราะห์เป็นสาขาวิชาที่ศึกษาเกี่ยวกับองค์ประกอบของดาวเคราะห์'\n",
    "a = word_tokenize(text,engine='ulmfit')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#integrated into pythainlp.ulmfit.utils\n",
    "from fastai.text.transform import *\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.util import normalize as normalize_char_order\n",
    "\n",
    "class ThaiTokenizer(BaseTokenizer):\n",
    "    \"Wrapper around a newmm tokenizer to make it a `BaseTokenizer`.\"\n",
    "    def __init__(self, lang = 'th'):\n",
    "        self.lang = lang\n",
    "    def tokenizer(self, t):\n",
    "        return(word_tokenize(t,engine='ulmfit'))\n",
    "    def add_special_cases(self, toks):\n",
    "        pass\n",
    "    \n",
    "def replace_rep_after(t):\n",
    "    \"Replace repetitions at the character level in `t` after the repetition\"\n",
    "    def _replace_rep(m):\n",
    "        c,cc = m.groups()\n",
    "        return f'{c} {TK_REP} {len(cc)+1} '\n",
    "    re_rep = re.compile(r'(\\S)(\\1{3,})')\n",
    "    return re_rep.sub(_replace_rep, t)\n",
    "\n",
    "def rm_useless_newlines(t):\n",
    "    \"Remove multiple newlines in `t`.\"\n",
    "    return re.sub('[\\n]{2,}', ' ', t)\n",
    "\n",
    "def rm_brackets(t):\n",
    "    \"Remove all empty brackets from `t`.\"\n",
    "    new_line = re.sub('\\(\\)','',t)\n",
    "    new_line = re.sub('\\{\\}','',new_line)\n",
    "    new_line = re.sub('\\[\\]','',new_line)\n",
    "    return(new_line)\n",
    "\n",
    "#in case we want to add more specific rules for thai\n",
    "pre_rules_th = [fix_html, replace_rep_after, normalize_char_order, \n",
    "                spec_add_spaces, rm_useless_spaces, rm_useless_newlines, rm_brackets]\n",
    "post_rules_th = [replace_all_caps, deal_caps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Bunch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained the language model based on 40M/200k/200k tokens of train-validation-test split from [Thai Wikipedia Dump](https://dumps.wikimedia.org/thwiki/latest/thwiki-latest-pages-articles.xml.bz2). Tokens are generated and numericalized filtering all words with frequency more than 3 and at maximum vocab size of 60,000 (plus unknown and padding tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = Tokenizer(tok_func = ThaiTokenizer, lang = 'th', pre_rules = pre_rules_th, post_rules=post_rules_th)\n",
    "processor = [TokenizeProcessor(tokenizer=tt, chunksize=10000, mark_fields=False),\n",
    "            NumericalizeProcessor(vocab=None, max_vocab=60000, min_freq=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = (ItemLists(model_path, \n",
    "#     TextList.from_df(train_df, model_path, cols=['texts'], processor=processor),\n",
    "#     TextList.from_df(valid_df, model_path, cols=['texts'], processor=processor))\n",
    "#     .label_for_lm()\n",
    "#     .add_test(TextList.from_df(test_df, model_path, cols=['texts'], processor=processor))\n",
    "#     .databunch(bs=64))\n",
    "# data.sanity_check()\n",
    "# data.save('thwiki_lm_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53307, 314, 267)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data(model_path,'thwiki_lm_data.pkl')\n",
    "data.sanity_check()\n",
    "len(data.train_ds), len(data.valid_ds), len(data.test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>คือ พ.ศ. 2412 ) เป็น พระราชธิดา พระองค์ สุดท้าย ใน พระ บาท สมเด็จ พระ จอมเกล้า เจ้า อยู่ หัว ประสูติ แต่ จ้า จอมมารดา ห่วง ธิดา ขุน เทพ ฯ กับ เก ษ มี พระ เชษฐ ภคินี พระ เชษฐา ร่วม เจ้าจอมมารดา เดียวกัน 2 พระองค์ คือ พระเจ้า บรมวงศ์ เธอ พระองค์ เจ้า บุษบัน บัว ผัน และ พระเจ้า บรมวงศ์ เธอ พระองค์ เจ้า ไช ยัน ตม งคล กรมหมื่น มหิศร ราช หฤทัย พระองค์ ประสูติ หลัง สมเด็จ พระ บรม ชนก</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>มานัต = ลัก ซอ ร์= ลัก ซอ ร์ ลัก ซอ ร์(;) เป็น นคร ในประเทศ อียิปต์ เป็น เมืองหลวง ของ เขต ผู้ว่า การลัก ซอ ร์ มี ประชากร 487 @,@ 896 คน ( ค.ศ. 2010 ) เมือง มี พื้นที่ ราว 416 ตร. กม. ( 161 ตร. ไมล์ ) เป็น สถาน ที่ตั้ง ของ เมือง อียิปต์ โบราณ เมือง ที บส์ อาจ กล่าว ได้ ว่า เป็น \" พิพิธภัณฑ์ เปิด โล่ง ที่ ใหญ่ ที่สุด ของ โลก \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>จาก การ ทำความเข้าใจ ธรรมชาติ ของ xxunk ใน เชิง เคมี ทำให้ แพทย์ สามารถ ค้นพบ วิธี การรักษา โรคติดต่อ ได้การ สนับสนุน ทางการแพทย์ . แพ รา เซ ลซัส เป็น ผู้ริเริ่ม การ ใช้ แร่ธาตุ และ สารเคมี ใน ทางการแพทย์ ใน ทาง ลึกลับ เขา มองว่า โรคภัยไข้เจ็บ และ สุขภาพ นั้น ขึ้นอยู่กับ ความ ลงตัว ของ มนุษย์ และ ธรรมชาติ เขา ใช้ วิธี ที่ แตกต่าง ไป จาก คนอื่น ก่อนหน้านี้ การ ใช้การ เปรียบเทียบ นี้ ไม่ได้ อยู่ ใน ลักษณะ ของ จิตวิญญาณ บริสุทธิ์ แต่</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ส์ 3 แอม บิ ชัน ส์= เดอะ ซิม ส์ 3 แอม บิ ชัน ส์ เดอะ ซิม ส์ 3 แอม บิ ชัน ส์ เป็น ภาค เสริม ตัว ที่ 2 ของ เกม เดอะ ซิม ส์ 3 สำหรับ ประเทศไทย มี การ วาง จำหน่าย ใน วันที่ 1 มิถุนายน พ.ศ. 2553 \"' เดอะ ซิม ส์ 3 แอม บิ ชัน ส์\" มา พร้อมกับ โหมด ใหม่ ซึ่ง ผู้ เล่น สามารถ เข้า ไปดู และ ควบคุม การทำงาน ของ ชาว</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>อื่น . อักษร แบบ อื่น ของ อิ คือ คะ นะ ขนาดเล็ก xxunkxxunk ใช้ สำหรับ แสดง เสียง ภาษาต่างประเทศ ของ ญี่ปุ่น เช่น xxunk ( วิ ), xxunk (ค วิ ), xxunk ( ซิ ), xxunkxxunkxxunk ( ดิ ), xxunkxxunk หรือ ใช้ สำหรับ ลากเสียง สระ อิ ให้ ยาว ขึ้น เป็น อี ภาษา ไอ นุ ใช้ คะ ตะ กะ นะ ขนาดเล็ก xxunk เป็น พยัญชนะ สะกด เหมือน การ สะกด ด้วย - ย และ อ่าน ออกเสียง</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[    2,    42,    36,  ..., 13392,    57,    31],\n",
       "         [   24,   627,    30,  ...,   312,   565,    13],\n",
       "         [   11,   266,    25,  ...,  3390,    10,    21],\n",
       "         ...,\n",
       "         [ 3166, 14325,    34,  ...,  2759,    12,  2057],\n",
       "         [  519,    20,     9,  ...,   115, 10305,    10],\n",
       "         [ 7289,   187,   321,  ...,    16, 10132, 10132]], device='cuda:0'),\n",
       " tensor([[   42,    36,  5499,  ...,    57,    31,    56],\n",
       "         [  627,    30,   160,  ...,   565,    13,  6010],\n",
       "         [  266,    25,  1380,  ...,    10,    21,  3993],\n",
       "         ...,\n",
       "         [14325,    34, 25768,  ...,    12,  2057, 12467],\n",
       "         [   20,     9,   316,  ..., 10305,    10,    48],\n",
       "         [  187,   321,    78,  ..., 10132, 10132, 30111]], device='cuda:0')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data.test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(data.vocab.itos, open(f'{model_path}models/thwiki_itos.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10616, 7258, 1339]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_lm = data.vocab\n",
    "vocab_lm.numericalize(word_tokenize('สวัสดีครับพี่น้อง', engine='ulmfit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'สวัสดี ครับ พี่น้อง'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_lm.textify([10616, 7258, 1339])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Modeling\n",
    "\n",
    "We train the language model according to the [ULMFit paper](https://arxiv.org/abs/1801.06146). We use the name hyperparameters as [n-waves/ulmfit-multilingual](https://github.com/n-waves/ulmfit-multilingual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(emb_sz=400, n_hid=1550, n_layers=4, pad_token=1, qrnn=False, tie_weights=True, out_bias=True,\n",
    "             output_p=0.25, hidden_p=0.1, input_p=0.2, embed_p=0.02, weight_p=0.15)\n",
    "trn_args = dict(drop_mult=0.9, clip=0.12, alpha=2, beta=1)\n",
    "\n",
    "learn = language_model_learner(data, AWD_LSTM, config=config, pretrained=False, **trn_args)\n",
    "learn.opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "learn.callback_fns += [partial(CSVLogger, filename=f\"{model_path}/logs\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 2.09E-03\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.freeze_to(-1)\n",
    "# learn.fit_one_cycle(1, 1e-2, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.unfreeze()\n",
    "# learn.fit_one_cycle(10, 1e-3, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| epoch | train_loss | valid_loss | accuracy |\n",
    "|-------|------------|------------|----------|\n",
    "| 1     | 5.689881   | 5.479321   | 0.176962 |\n",
    "| 2     | 5.14165    | 4.914922   | 0.223256 |\n",
    "| 3     | 4.945699   | 4.661891   | 0.242748 |\n",
    "| 4     | 4.708307   | 4.471861   | 0.261348 |\n",
    "| 5     | 4.636846   | 4.337728   | 0.273785 |\n",
    "| 6     | 4.487616   | 4.237517   | 0.285252 |\n",
    "| 7     | 4.370384   | 4.161622   | 0.293807 |\n",
    "| 8     | 4.291326   | 4.100852   | 0.30109  |\n",
    "| 9     | 4.267814   | 4.071167   | 0.303888 |\n",
    "| 10    | 4.217663   | 4.065733   | 0.304822 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.unfreeze()\n",
    "# learn.fit_one_cycle(10, 1e-3/3, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| epoch | train_loss | valid_loss | accuracy |\n",
    "|-------|------------|------------|----------|\n",
    "| 1     | 4.179729   | 4.052608   | 0.304963 |\n",
    "| 2     | 4.16306    | 4.047963   | 0.305331 |\n",
    "| 3     | 4.184966   | 4.044866   | 0.305482 |\n",
    "| 4     | 4.218517   | 4.023499   | 0.307901 |\n",
    "| 5     | 4.183966   | 4.001536   | 0.310346 |\n",
    "| 6     | 4.165901   | 3.985509   | 0.312516 |\n",
    "| 7     | 4.091527   | 3.966779   | 0.315573 |\n",
    "| 8     | 4.078772   | 3.952682   | 0.317021 |\n",
    "| 9     | 4.020618   | 3.944576   | 0.318096 |\n",
    "| 10    | 4.043382   | 3.94425    | 0.317961 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.save('thwiki_lm')\n",
    "# learn.save_encoder('thwiki_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eyeballing Test\n",
    "We perform eyeballing test by having the model \"fill in the blanks\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from fastai import *    \n",
    "from fastai.text import * \n",
    "from fastai.callbacks import CSVLogger\n",
    "data_path = 'th-all-unk/'\n",
    "model_path = 'thwiki_data/'\n",
    "\n",
    "#data\n",
    "data = load_data(model_path,'thwiki_lm_data.pkl')\n",
    "data.sanity_check()\n",
    "\n",
    "#lm\n",
    "config = dict(emb_sz=400, n_hid=1550, n_layers=4, pad_token=1, qrnn=False, tie_weights=True, out_bias=True,\n",
    "             output_p=0.25, hidden_p=0.1, input_p=0.2, embed_p=0.02, weight_p=0.15)\n",
    "trn_args = dict(drop_mult=0.9, clip=0.12, alpha=2, beta=1)\n",
    "\n",
    "learn = language_model_learner(data, AWD_LSTM, config=config, pretrained=False, **trn_args)\n",
    "learn.opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "\n",
    "#load weights\n",
    "learn.load('thwiki_lm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'สวัสดีครับ พี่น้องเสื้อแดง=รองเท้าแดงเสื้อแดง(อังกฤษ:St.โก้)เป็นภาพยนตร์ไทยแนวตลก-แฟนตาซีออกฉายในปีพ.ศ.2544กำกับโดยยุทธนามุกดาสนิทนำแสดงโดยสันติสุขพรหมศิริ,สุวนันท์คงยิ่ง,สุรชัยจันทิมาธร,บุญชูสกุลเจริญสุข,สุกัญญาวงศ์สวัสดิ์,สุกัญญาไชยศิริ,วิยะดาอุมารินทร์,นิรุตติ์ศิริจรรยา,อุบลรัตน์ปิยะศิริ,สุรชัยจันทิมาธร,รัช'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('สวัสดีครับ พี่น้องเสื้อ',100, sep='', temperature = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "We extract the embedding layer of the encoder to be used in the same manner as `word2vec`. We can also create sentence vector by summing or averaging the vectors. For more details about `word2vec` use cases, see`word2vec_examples.ipynb`. Note that we use word vectors from `v0.1` since it was trained specifically for the purpose and has comparable dimensions to `fastText` embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T17:14:19.257675Z",
     "start_time": "2018-01-24T17:14:19.219043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60003, 400)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how we extracted the embeddings\n",
    "emb_weights = list(learn.model.named_parameters())[0][1]\n",
    "emb_np = to_np(emb_weights.data)\n",
    "emb_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format(f'{model_path}models/thai2vec.vec',binary=False,\n",
    "                                         unicode_errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_word2vec_format(f'{model_path}models/thai2vec.vec',f'{model_path}models/thai2vec.vocab',False)\n",
    "model.save_word2vec_format(f'{model_path}models/thai2vec.bin',None,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get document vector from the language model by applying the encoder to a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tt = ThaiTokenizer()\n",
    "def document_vector(ss, learn, data):\n",
    "    s = tt.tokenizer(ss)\n",
    "    t = torch.tensor(data.vocab.numericalize(s), requires_grad=False).to(device)\n",
    "    m = learn.model[0].encoder.to(device)\n",
    "    res = m(t).mean(0).cpu().detach().numpy()\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.066298,  0.307813,  0.246051,  0.008683, ..., -0.058363,  0.133258, -0.289954, -1.770246], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = 'วันนี้วันดีปีใหม่'\n",
    "document_vector(ss,learn,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.066298,  0.307813,  0.246051,  0.008683, ..., -0.058363,  0.133258, -0.289954, -1.770246], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp.ulmfit import *\n",
    "document_vector('วันนี้วันดีปีใหม่',learn,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
